{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOM-VAE vs \u03b2-VAE Comparison\n",
    "\n",
    "**Hypothesis**: BOM achieves comparable or better results than \u03b2-VAE without requiring hyperparameter tuning.\n",
    "\n",
    "**Adaptive squeeze rule**:\n",
    "```\n",
    "squeeze_amount = (s_min - 0.5) * k\n",
    "```\n",
    "- When s_min = 0.9: squeeze aggressively\n",
    "- When s_min = 0.55: squeeze gently  \n",
    "- When s_min \u2264 0.5: stop squeezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared VAE architecture\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 2, 1), nn.GroupNorm(8, 32), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(32, 64, 3, 2, 1), nn.GroupNorm(8, 64), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 3, 2, 1), nn.GroupNorm(8, 128), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, 3, 2, 1), nn.GroupNorm(8, 256), nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(256*4*4, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(256*4*4, latent_dim)\n",
    "        self.fc_dec = nn.Linear(latent_dim, 256*4*4)\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 3, 2, 1, 1), nn.GroupNorm(8, 128), nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(128, 64, 3, 2, 1, 1), nn.GroupNorm(8, 64), nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(64, 32, 3, 2, 1, 1), nn.GroupNorm(8, 32), nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(32, 1, 3, 2, 1, 1), nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.enc(x).view(x.size(0), -1)\n",
    "        mu, logvar = self.fc_mu(h), self.fc_logvar(h)\n",
    "        z = mu + torch.randn_like(mu) * torch.exp(0.5 * logvar)\n",
    "        return self.dec(self.fc_dec(z).view(-1, 256, 4, 4)), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Data\ntransform = transforms.Compose([transforms.Resize(64), transforms.ToTensor()])\ntrain_data = datasets.MNIST('./data', train=True, download=True, transform=transform)\ntest_data = datasets.MNIST('./data', train=False, download=True, transform=transform)\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2)\ntest_loader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2)\nprint(f\"Train: {len(train_loader)} batches, Test: {len(test_loader)} batches\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(x, x_recon, mu, logvar):\n",
    "    \"\"\"Compute MSE, KL, and sharpness.\"\"\"\n",
    "    B = x.size(0)\n",
    "    mse = F.mse_loss(x_recon, x, reduction='none').view(B, -1).mean(1)\n",
    "    kl = -0.5 * (1 + logvar - mu.pow(2) - logvar.exp()).sum(1)\n",
    "    dx = torch.abs(x_recon[:,:,:,1:] - x_recon[:,:,:,:-1])\n",
    "    dy = torch.abs(x_recon[:,:,1:,:] - x_recon[:,:,:-1,:])\n",
    "    sharp = (dx.mean([1,2,3]) + dy.mean([1,2,3])) / 2\n",
    "    return mse, kl, sharp\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    \"\"\"Evaluate model on test set.\"\"\"\n",
    "    model.eval()\n",
    "    all_mse, all_kl, all_sharp = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch[0].to(device)\n",
    "            x_recon, mu, logvar = model(x)\n",
    "            mse, kl, sharp = compute_metrics(x, x_recon, mu, logvar)\n",
    "            all_mse.extend(mse.cpu().numpy())\n",
    "            all_kl.extend(kl.cpu().numpy())\n",
    "            all_sharp.extend(sharp.cpu().numpy())\n",
    "    \n",
    "    return {\n",
    "        'mse': np.mean(all_mse),\n",
    "        'kl': np.mean(all_kl),\n",
    "        'sharp': np.mean(all_sharp),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## \u03b2-VAE Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_beta_vae(model, loader, device, beta, n_epochs=20):\n",
    "    \"\"\"\n",
    "    Standard \u03b2-VAE training.\n",
    "    Loss = MSE + \u03b2 * KL\n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    history = []\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss, epoch_mse, epoch_kl = [], [], []\n",
    "        \n",
    "        pbar = tqdm(loader, desc=f\"\u03b2-VAE (\u03b2={beta}) Epoch {epoch}\")\n",
    "        for batch in pbar:\n",
    "            x = batch[0].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            x_recon, mu, logvar = model(x)\n",
    "            \n",
    "            mse, kl, sharp = compute_metrics(x, x_recon, mu, logvar)\n",
    "            loss = mse.mean() + beta * kl.mean()\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss.append(loss.item())\n",
    "            epoch_mse.append(mse.mean().item())\n",
    "            epoch_kl.append(kl.mean().item())\n",
    "            \n",
    "            history.append({\n",
    "                'mse': mse.mean().item(),\n",
    "                'kl': kl.mean().item(),\n",
    "                'sharp': sharp.mean().item(),\n",
    "            })\n",
    "            \n",
    "            pbar.set_postfix({'loss': f\"{loss.item():.4f}\", 'mse': f\"{mse.mean().item():.4f}\", 'kl': f\"{kl.mean().item():.0f}\"})\n",
    "        \n",
    "        print(f\"  Epoch {epoch}: loss={np.mean(epoch_loss):.4f}, mse={np.mean(epoch_mse):.4f}, kl={np.mean(epoch_kl):.0f}\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## BOM-VAE Training with Adaptive Squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_constraint_lower_better(value, floor):\n",
    "    \"\"\"Score for objectives where lower is better (MSE).\"\"\"\n",
    "    return (floor - value) / floor\n",
    "\n",
    "\n",
    "def regular_constraint_higher_better(value, ceiling):\n",
    "    \"\"\"Score for objectives where higher is better (sharpness).\"\"\"\n",
    "    return value / ceiling\n",
    "\n",
    "\n",
    "def box_constraint(value, floor_low, optimum, floor_high):\n",
    "    \"\"\"Score for objectives that need to stay in a range (KL).\"\"\"\n",
    "    left = (value - floor_low) / (optimum - floor_low)\n",
    "    right = (floor_high - value) / (floor_high - optimum)\n",
    "    return torch.minimum(left, right)\n",
    "\n",
    "\n",
    "def compute_bom_loss(x, x_recon, mu, logvar, mse_floor, kl_floor_low, kl_optimum, kl_floor_high, sharp_ceiling):\n",
    "    \"\"\"Compute BOM loss.\"\"\"\n",
    "    mse, kl, sharp = compute_metrics(x, x_recon, mu, logvar)\n",
    "    \n",
    "    mse_score = regular_constraint_lower_better(mse, mse_floor)\n",
    "    kl_score = box_constraint(kl, kl_floor_low, kl_optimum, kl_floor_high)\n",
    "    sharp_score = regular_constraint_higher_better(sharp, sharp_ceiling)\n",
    "    \n",
    "    scores = torch.stack([mse_score, kl_score, sharp_score], dim=1)\n",
    "    s_min, min_idx = torch.min(scores, dim=1)\n",
    "    \n",
    "    violations = (s_min <= 0).sum().item()\n",
    "    \n",
    "    metrics = {\n",
    "        'mse': mse.mean().item(),\n",
    "        'kl': kl.mean().item(),\n",
    "        'sharp': sharp.mean().item(),\n",
    "        'mse_score': mse_score.mean().item(),\n",
    "        'kl_score': kl_score.mean().item(),\n",
    "        'sharp_score': sharp_score.mean().item(),\n",
    "        's_min': s_min.mean().item(),\n",
    "        'violations': violations,\n",
    "    }\n",
    "    \n",
    "    if violations > 0:\n",
    "        return None, metrics\n",
    "    \n",
    "    loss = -torch.log(s_min).mean()\n",
    "    names = ['mse', 'kl', 'sharp']\n",
    "    metrics['bottleneck'] = names[torch.bincount(min_idx, minlength=3).argmax().item()]\n",
    "    metrics['loss'] = loss.item()\n",
    "    \n",
    "    return loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_bom(model, loader, device, n_batches=50):\n",
    "    \"\"\"Calibrate BOM constraints based on model's current outputs.\"\"\"\n",
    "    model.train()\n",
    "    all_mse, all_kl, all_sharp = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(loader):\n",
    "            if i >= n_batches: break\n",
    "            x = batch[0].to(device)\n",
    "            x_recon, mu, logvar = model(x)\n",
    "            mse, kl, sharp = compute_metrics(x, x_recon, mu, logvar)\n",
    "            all_mse.extend(mse.cpu().numpy())\n",
    "            all_kl.extend(kl.cpu().numpy())\n",
    "            all_sharp.extend(sharp.cpu().numpy())\n",
    "    \n",
    "    mse_arr = np.array(all_mse)\n",
    "    kl_arr = np.array(all_kl)\n",
    "    sharp_arr = np.array(all_sharp)\n",
    "    \n",
    "    params = {\n",
    "        'mse_floor': mse_arr.max() * 2.0,\n",
    "        'kl_floor_low': kl_arr.min() * 0.1,\n",
    "        'kl_optimum': kl_arr.mean(),\n",
    "        'kl_floor_high': kl_arr.max() * 50.0,  # Very loose initially\n",
    "        'sharp_ceiling': sharp_arr.mean(),\n",
    "    }\n",
    "    \n",
    "    print(f\"Calibration: MSE={mse_arr.mean():.4f}, KL={kl_arr.mean():.1f}, Sharp={sharp_arr.mean():.4f}\")\n",
    "    print(f\"Initial constraints: mse_floor={params['mse_floor']:.4f}, kl_box=[{params['kl_floor_low']:.1f}, {params['kl_optimum']:.1f}, {params['kl_floor_high']:.1f}]\")\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def train_bom_vae(model, loader, device, n_epochs=20):\n    \"\"\"\n    BOM-VAE training with adaptive squeeze.\n    \n    Squeeze rule: squeeze_amount = (s_min - 0.5) * k\n    - s_min > 0.5: squeeze proportionally\n    - s_min <= 0.5: don't squeeze\n    \"\"\"\n    # Calibrate\n    params = calibrate_bom(model, loader, device)\n    print('Recalibrated BOM constraints for current architecture.')\n    \n    mse_floor = params['mse_floor']\n    kl_floor_low = params['kl_floor_low']\n    kl_optimum = params['kl_optimum']\n    kl_floor_high = params['kl_floor_high']\n    sharp_ceiling = params['sharp_ceiling']\n    \n    # Targets\n    # Per-dimension KL targets (tuned for latent_dim=128 => totals 50/80/150)\n    kl_floor_low_per_dim = 0.390625\n    kl_optimum_per_dim = 0.625\n    kl_floor_high_per_dim = 1.171875\n    target_kl_floor_low = kl_floor_low_per_dim * model.latent_dim\n    target_kl_optimum = kl_optimum_per_dim * model.latent_dim\n    target_kl_floor_high = kl_floor_high_per_dim * model.latent_dim\n    if kl_floor_high < target_kl_floor_high:\n        print('\u26a0\ufe0f KL upper bound below target; consider loosening constraints.')\n    else:\n        print('\u2705 KL targets appear attainable with recalibrated bounds.')\n    \n    # Adaptive squeeze settings\n    squeeze_k = 0.5  # Gain factor\n    min_s_min_for_squeeze = 0.5\n    squeeze_start_epoch = 3\n    \n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n    history = []\n    \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        epoch_loss, epoch_s_min = [], []\n        epoch_violations = 0\n        \n        pbar = tqdm(loader, desc=f\"BOM-VAE Epoch {epoch}\")\n        for batch in pbar:\n            x = batch[0].to(device)\n            \n            optimizer.zero_grad()\n            x_recon, mu, logvar = model(x)\n            \n            loss, metrics = compute_bom_loss(\n                x, x_recon, mu, logvar,\n                mse_floor, kl_floor_low, kl_optimum, kl_floor_high, sharp_ceiling\n            )\n            \n            if loss is not None:\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                optimizer.step()\n                epoch_loss.append(metrics['loss'])\n                epoch_s_min.append(metrics['s_min'])\n            else:\n                epoch_violations += metrics['violations']\n            \n            history.append(metrics)\n            pbar.set_postfix({'s_min': f\"{metrics['s_min']:.3f}\", 'kl': f\"{metrics['kl']:.0f}\"})\n        \n        avg_s_min = np.mean(epoch_s_min) if epoch_s_min else 0\n        print(f\"  Epoch {epoch}: s_min={avg_s_min:.3f}, violations={epoch_violations}, mse={metrics['mse']:.4f}, kl={metrics['kl']:.0f}\")\n        print(f\"    KL box: [{kl_floor_low:.1f}, {kl_optimum:.1f}, {kl_floor_high:.1f}]\")\n        \n        # Adaptive squeeze\n        if epoch >= squeeze_start_epoch and avg_s_min > min_s_min_for_squeeze:\n            squeeze_amount = (avg_s_min - min_s_min_for_squeeze) * squeeze_k\n            squeeze_factor = 1.0 - squeeze_amount  # e.g., s_min=0.9 -> factor=0.8\n            squeeze_factor = max(0.5, squeeze_factor)  # Don't squeeze more than 50%\n            \n            print(f\"    \ud83d\udd27 Squeeze: s_min={avg_s_min:.3f} -> factor={squeeze_factor:.2f}\")\n            \n            # Squeeze MSE floor\n            mse_floor *= squeeze_factor\n            \n            # Squeeze KL box toward targets\n            if kl_floor_low < target_kl_floor_low:\n                kl_floor_low += (target_kl_floor_low - kl_floor_low) * (1 - squeeze_factor)\n            if kl_optimum < target_kl_optimum:\n                kl_optimum += (target_kl_optimum - kl_optimum) * (1 - squeeze_factor)\n            if kl_floor_high > target_kl_floor_high:\n                kl_floor_high -= (kl_floor_high - target_kl_floor_high) * (1 - squeeze_factor)\n    \n    return history\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 20\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u03b2-VAE with different \u03b2 values\n",
    "betas = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "for beta in betas:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training \u03b2-VAE with \u03b2={beta}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    model = VAE(latent_dim=128).to(device)\n",
    "    history = train_beta_vae(model, train_loader, device, beta=beta, n_epochs=N_EPOCHS)\n",
    "    test_metrics = evaluate(model, test_loader, device)\n",
    "    \n",
    "    results[f'beta_{beta}'] = {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'test': test_metrics,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nTest results: MSE={test_metrics['mse']:.4f}, KL={test_metrics['kl']:.1f}, Sharp={test_metrics['sharp']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOM-VAE\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training BOM-VAE (no \u03b2 tuning required)\")\n",
    "print('='*60)\n",
    "\n",
    "model_bom = VAE(latent_dim=128).to(device)\n",
    "history_bom = train_bom_vae(model_bom, train_loader, device, n_epochs=N_EPOCHS)\n",
    "test_metrics_bom = evaluate(model_bom, test_loader, device)\n",
    "\n",
    "results['bom'] = {\n",
    "    'model': model_bom,\n",
    "    'history': history_bom,\n",
    "    'test': test_metrics_bom,\n",
    "}\n",
    "\n",
    "print(f\"\\nTest results: MSE={test_metrics_bom['mse']:.4f}, KL={test_metrics_bom['kl']:.1f}, Sharp={test_metrics_bom['sharp']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Method':<20} {'MSE':>10} {'KL':>10} {'Sharpness':>12}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for name, data in results.items():\n",
    "    t = data['test']\n",
    "    print(f\"{name:<20} {t['mse']:>10.4f} {t['kl']:>10.1f} {t['sharp']:>12.4f}\")\n",
    "\n",
    "print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for name, data in results.items():\n",
    "    h = data['history']\n",
    "    label = name.replace('_', '=')\n",
    "    \n",
    "    axes[0].plot([x['mse'] for x in h], label=label, alpha=0.8)\n",
    "    axes[1].plot([x['kl'] for x in h], label=label, alpha=0.8)\n",
    "    axes[2].plot([x['sharp'] for x in h], label=label, alpha=0.8)\n",
    "\n",
    "axes[0].set_title('MSE (\u2193 better)')\n",
    "axes[0].set_xlabel('Step')\n",
    "axes[0].legend()\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "axes[1].set_title('KL Divergence')\n",
    "axes[1].set_xlabel('Step')\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].set_title('Sharpness (\u2191 better)')\n",
    "axes[2].set_xlabel('Step')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_comparison.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pareto plot: MSE vs KL\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(results)))\n",
    "\n",
    "for (name, data), color in zip(results.items(), colors):\n",
    "    t = data['test']\n",
    "    marker = 's' if 'beta' in name else 'o'\n",
    "    size = 100 if 'bom' in name else 60\n",
    "    plt.scatter(t['mse'], t['kl'], s=size, c=[color], marker=marker, label=name.replace('_', '='), edgecolors='black')\n",
    "\n",
    "plt.xlabel('MSE (\u2193 better)')\n",
    "plt.ylabel('KL (moderate is better)')\n",
    "plt.title('Pareto Front: MSE vs KL')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('pareto_comparison.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Reconstructions comparison\ntest_batch = next(iter(test_loader))[0][:8].to(device)\n\nn_models = len(results)\nfig, axes = plt.subplots(n_models + 1, 8, figsize=(16, 2*(n_models+1)))\n\n# Original\nfor i in range(8):\n    axes[0, i].imshow(test_batch[i].cpu().squeeze(0))\n    axes[0, i].axis('off')\naxes[0, 0].set_ylabel('Original', fontsize=12)\n\n# Each model's reconstruction\nfor row, (name, data) in enumerate(results.items(), 1):\n    model = data['model']\n    model.eval()\n    with torch.no_grad():\n        recon, _, _ = model(test_batch)\n    \n    for i in range(8):\n        axes[row, i].imshow(recon[i].cpu().squeeze(0))\n        axes[row, i].axis('off')\n    axes[row, 0].set_ylabel(name.replace('_', '='), fontsize=12)\n\nplt.tight_layout()\nplt.savefig('reconstructions_comparison.png', dpi=150)\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Samples from prior comparison\nz = torch.randn(8, 128, device=device)\n\nn_models = len(results)\nfig, axes = plt.subplots(n_models, 8, figsize=(16, 2*n_models))\n\nfor row, (name, data) in enumerate(results.items()):\n    model = data['model']\n    model.eval()\n    with torch.no_grad():\n        samples = model.dec(model.fc_dec(z).view(-1, 256, 4, 4))\n    \n    for i in range(8):\n        axes[row, i].imshow(samples[i].cpu().squeeze(0))\n        axes[row, i].axis('off')\n    axes[row, 0].set_ylabel(name.replace('_', '='), fontsize=12)\n\nplt.suptitle('Samples from Prior (same z for all models)', fontsize=14)\nplt.tight_layout()\nplt.savefig('samples_comparison.png', dpi=150)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best \u03b2-VAE\n",
    "beta_results = {k: v for k, v in results.items() if 'beta' in k}\n",
    "bom_result = results['bom']\n",
    "\n",
    "# Best by MSE\n",
    "best_mse_beta = min(beta_results.items(), key=lambda x: x[1]['test']['mse'])\n",
    "print(f\"Best \u03b2-VAE by MSE: {best_mse_beta[0]} (MSE={best_mse_beta[1]['test']['mse']:.4f})\")\n",
    "print(f\"BOM-VAE MSE: {bom_result['test']['mse']:.4f}\")\n",
    "print()\n",
    "\n",
    "# Best by balanced score (low MSE, moderate KL, high sharp)\n",
    "def balanced_score(t):\n",
    "    # Lower MSE is better (invert)\n",
    "    # KL around 50-150 is good (penalty for too low or too high)\n",
    "    # Higher sharpness is better\n",
    "    mse_score = 1.0 / (t['mse'] + 0.001)\n",
    "    kl_score = 1.0 / (abs(t['kl'] - 100) + 10)  # Peak at KL=100\n",
    "    sharp_score = t['sharp']\n",
    "    return mse_score * kl_score * sharp_score\n",
    "\n",
    "best_balanced_beta = max(beta_results.items(), key=lambda x: balanced_score(x[1]['test']))\n",
    "print(f\"Best \u03b2-VAE by balanced score: {best_balanced_beta[0]}\")\n",
    "print(f\"  Score: {balanced_score(best_balanced_beta[1]['test']):.4f}\")\n",
    "print(f\"BOM-VAE balanced score: {balanced_score(bom_result['test']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONCLUSION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "\u03b2-VAE requires tuning \u03b2 to balance reconstruction vs regularization.\n",
    "Different \u03b2 values give different tradeoffs:\n",
    "- Low \u03b2 (0.0001): Good MSE, but KL may collapse or explode\n",
    "- High \u03b2 (0.1): Controlled KL, but poor reconstruction\n",
    "\n",
    "BOM-VAE automatically finds a balanced solution:\n",
    "- No \u03b2 hyperparameter to tune\n",
    "- Adaptive squeeze finds the Pareto frontier\n",
    "- All objectives are explicitly constrained\n",
    "\n",
    "The key insight: BOM optimizes the WORST objective at each step,\n",
    "preventing any single objective from being sacrificed.\n",
    "\"\"\")"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 }
}